
# PORTFOLIO
<p align="center">
  
Hello everyone! My name is Karyna Zubko.



<p> I am a certified Business Intelligence and Product Analyst with expertise in analyzing Product and Finance data, coming from Prop-tech and Media products. Feel free to explore my portfolio to overview more projects. I am passionate about data and knowledge about how things work, whether that be studying and researching business metrics, data leveraging techniques, and machine learning methods. </p>





# Get to Know Me 

### Click below to explore my CV

<p align="center">
<a href="https://github.com/KarinaZubko/Portfolio/blob/main/images/Zubko_Karyna_CV.pdf"><img src="images/CV_header.png"></a></p>

<hr>


### My Professional Experience 
<p align="left">
<a href="https://www.linkedin.com/in/karina-zubko/">LinkedIn</a>
  <p> Certified Business Intelligence and Product Analyst with 4 years of experience turning data into actionable insights. Skilled in analyzing Product and Finance data to optimize performance and drive strategic decisions. I excel in bridging teams through clear communication and delivering data-driven solutions that achieve measurable results. Work in real estate, finance, e-commerce, and user behavior data domains.</p>


# My Past Projects
<hr>

### [Tableau Dashboard: App Trial2Paid Analysis](https://public.tableau.com/app/profile/karyna5596/viz/Femia/Main#1)

<em> 
We calculated and analyzed the Trial2Paid metric - conversion from trial to payment. In particular, to cover the following issues:
- Calculated Trial2Paid in different segments, identified segments that are more likely to convert to payment.
- Calculated the share of trials that are canceled manually by users.
- Analyzed the day after the start of the trial when the user most often canceled.
 
<br> Project Workflow: 

<br> <strong> 1. Data Cleaning </strong>: Finding outliers and value ranges for each column.
<br> <strong> 2. Data Processing </strong>: Utilizing Python and Excel to clean and preprocess the data, splitting column values to get the additional data (prices, tariff duration, net revenue, discount revenue), and checking anomaly values.
<br> <strong> 3. Measures and Visualization </strong>: Using Tableau I created measures that calculated Trial2Paid conversions based on the business requirements, added cahrts and heat map that helps to identify user segments. It has highlighted the crucial points influenced by Trial2Paid User conversions and for the further hypothesis to increase it.
<br> <strong> 4. Reporting: </strong>

<br> Conclusion:

The share of trials that users cancel manually is 30.46%, which amounts to 3,046 users (2024 data). Most often, users cancel trials on the 2nd day after the start of the trial period.
But there are also cases when users cancel the trial the next day. For the given period, this is 671 users. And only 53 users (0.0053%) use 29 days of the trial before manually canceling it through the subscription settings.

<br> Key Skills:

Tableau
Product Data Analysis
Conversion Metrics
Data Visualisations
</p>

[Dataset reference - Data generated randomly](https://docs.google.com/spreadsheets/d/1Pm2ctSgghlMMSkAweL-kKCzNxP7DmJTWxEG6m6C8NMk/edit?gid=0#gid=0)

July, 2024
<hr>

### [Looker Dashboard: Ultra Marathon Finishers](https://lookerstudio.google.com/reporting/e5837fa5-1b7f-4136-a3af-a0d339000e15/page/ikM3D)

<em> 
This project showcases a comprehensive Data Analyst portfolio that leverages a variety of tools including Excel, Python, SQL, and Looker. The primary objective is to download, clean, and visualize data related to an ultra marathon event, providing valuable insights through detailed analysis and graphical representations.

 
<br> Project Workflow: 

<br> <strong> 1. Data Collection </strong>: Downloading the marathon data from online sources.
<br> <strong> 2. Data Cleaning : </strong>Utilizing Python and Excel to clean and preprocess the data, addressing issues such as missing values, incorrect data entries, and ensuring data consistency.
<br> <strong> 3. Data Analysis: </strong>Performing exploratory data analysis (EDA) using Python ([Link to Python Code](https://github.com/KarinaZubko/Portfolio/blob/main/Marathon/Marathon_Results.ipynb)) and SQL ([Link to SQL queries](https://github.com/KarinaZubko/Portfolio/blob/main/Marathon/Marathon_SQL.sql)) to uncover patterns, trends, and insights from the dataset.
<br> <strong> 4. Data Visualization: </strong>Creating comprehensive visualizations using Looker to illustrate key findings and make the data more accessible and understandable.
<br> <strong> 5. Reporting: </strong>Compiling the analysis and visualizations into a coherent report or dashboard that highlights the main insights and conclusions from the study.

<br> Conclusion:

This project not only demonstrates the technical skills required for data analysis but also provides practical insights into ultra marathon performance. Stay tuned for the subsequent project on the 100-mile ultra marathon, where even more in-depth analysis will be conducted.

<br> Key Skills:

Data cleaning and preprocessing, 
Data analysis and manipulation,
SQL querying,
Data visualization,
Dashboard creation.
</p>

[Dataset reference](https://ultrasignup.com/results_event.aspx?did=102259)

July, 2024
<hr>

### [Tableau Dashboard: Amazon Prime Video](https://public.tableau.com/app/profile/karyna5596/viz/AmazonPrimeVideo_16910027884160/Dashboard1)


<em> 
The data visualized using Tableau shows us the main information about the sales process in 4 regions. You can easily switch the region and work with the data brought to it. The following calculations were applied:
<em> 
  
<br> 1. <em> Understanding what content is available in different countries.
<br>
2. <em> Identifying similar content by matching text-based features
<br>
3. <em> Actors / Directors</em> and find interesting insights
<br>
4. Does <em> Amazon Prime</em> have more focus on TV Shows than movies in recent years?
</p>

[Dataset reference](https://www.kaggle.com/datasets/shivamb/amazon-prime-movies-and-tv-shows)

August, 2023
<hr>

### [AirBnb. Price prediction model for apartment in Lisbon](https://github.com/KarinaZubko/Portfolio/tree/main/AirBnb%20Price%20Prediction)


<p>
This project analyzed the factors that may have significant roles in affecting prices, which will provide comprehensive insights about Airbnb rental price valuation across the Lisbon area.
<p>
The prices and all info about listings I took from opensource
  <a href="http://insideairbnb.com/get-the-data/"> InsideAirBn </a> 
    website. For modeling, I used Linear Regression and Multiple Regression.
<p> <em>Ploty, MatplotLib, Seaborn, Missingno, HeatMap, NumPy, SKLearn</em>

The analysis consists of:

<br> 1. Data Cleaning
<br> 2. EDA
<br> 3. Correlation
<br> 4. Clusterization
<br> 5. Check numeric field distribution
<br> 6. Top Listing count
<br> 7. Map Visualization (Based on Listings & Based on prices)
<br> 8. Modeling (Linear Regression & Multiple Regression)
</p>

[Dataset reference](http://insideairbnb.com/get-the-data/)

April, 2023
<hr>

### [Real or Not? NLP with Disaster Tweets](https://github.com/KarinaZubko/Portfolio/blob/main/NLP/NLP_Twitter_spam_amalysis.ipynb)


<p>
Natural Language Processing with Disaster Tweets. Predict which Tweets are about real disasters and which ones are not. 
Completed in terms of Kaggle Competition.
<p>
Twitter has become an important communication channel in times of emergency.
The ubiquitousness of smartphones enables people to announce an emergency they’re observing in real-time. Because of this, more agencies are interested in programmatically monitoring Twitter (i.e. disaster relief organizations and news agencies). During the learning, I have been challenged to build a machine learning model that predicts which Tweets are about real disasters and which ones aren’t.
<p> <em>Ploty, NLP, NLTK, MatplotLib, NumPy, SKLearn, Keras</em>

The analysis consists of:

<br> 1. Libraries Import
<br> 2. Dataset Import
<br> 3. Cleaning and filling in missing data
<br> 4. Dataset Visualisation
<br> 5. Vecotisation
<br> 6. Modeling
<br> 7. Long-short time memory networks
<br> 8. Practical case: Dissaster Tweets
 </p>

[Dataset reference](https://www.kaggle.com/code/speccco/roller-coaster-eda/input)

April, 2023
<hr>

### [Coaster EDA](https://github.com/KarinaZubko/Portfolio/blob/main/Coaster_EDA/EDA.ipynb)


<p>
Exploratory Data Analysis is a necessary tool for any data scientist. The analysis ran using <em>pandas&numpy</em> packages, <em>matplotlib</em>  visualization library and <em>seaborn</em> package for plots creation. The analysis consists of:

<br> 1. Data Understanding
<br> 2. Data Preparation
<br> 3. Plotting Feature Distributions
<br> 4. Feature Relationships
<br> 5. Data Insight
 </p>

[Dataset reference](https://www.kaggle.com/code/speccco/roller-coaster-eda/input)

March, 2023
<hr>

### [Tableau Dashboard: Sales Tracking by Regions](https://public.tableau.com/app/profile/karyna5596/viz/SalesTrackinngbyRegions/Dashboard1?publish=yes)


<p>
The data visualized using Tableau shows us the main information about the sales process in 4 regions. You can easily switch the region and work with the data brings to it. The following calculations were applied:
  
<br> 1. <em> Total Sales, Total Profit, Total Orders, Turn Over percentage </em> for the current year + <em> % of Changes</em> compared with the previous year.
<br>
2. <em>Daily number of Sales deals</em> for selected region
<br>
3. <em> Top 5 categories of Sales</em> for selected region
<br>
4. <em> Order Details with profit and sales calculations</em> for selected region
 </p>


March, 2023

<hr>

### [Employee Exhaustion Analysis](https://github.com/KarinaZubko/Portfolio/blob/main/Employee%20Exhaustion%20Analysis/Employee_Exhaustion_Analysis_using_ML.ipynb)


<p>
In this project, machine learning and deep learning algorithms are used to predict employee attrition. The following steps were taken:
  
<br>1. Including necessary libraries and importing datasets.
<br>2. Exploratory Data Analysis
<br>3. Data Splitting
<br>4. Data Modeling

[Dataset reference](https://ieee-dataport.org/documents/ibm-hr-analytics-employee-attrition-performance)

February, 2023
<hr>

### [E-Commerce Shipping Prediction](https://github.com/KarinaZubko/Portfolio/blob/main/E_Commerce_Shipping/Prediction.ipynb)


<p>
This shipment tracking data will instantly answer the next questions:

<br> 1 - What was the customer rating? Was the product delivered on time?
<br> 2 - Does it respond to the customer's request?
<br> 3 - If the importance of the product is high, does it have the highest rating, was it delivered on time?
 </p>

[Dataset reference](https://www.kaggle.com/prachi13/customer-analytics)

February, 2023
<hr>
